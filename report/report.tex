\documentclass[journal]{IEEEtran}

\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote.
% If that is unneeded, please comment it out.
\usepackage[backend=biber,style=ieee,natbib=true]{biblatex} 
\bibliography{references.bib}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm2e}
\usepackage{graphicx}
\graphicspath{ {../images/} }
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\setlength {\marginparwidth }{2cm}
\usepackage{todonotes}
\usepackage{booktabs}
\usepackage{csvsimple}
\usepackage{siunitx}

\newcommand\percentage[2][round-precision = 2]{% default precision: 2
    \SI[round-mode = places,
        scientific-notation = fixed, fixed-exponent = 0,
        output-decimal-marker={.}, #1]{#2e2}{\percent}%
}
\begin{document}

\title{Automated Labeling of Pulsar Star Candidates}

\author{\IEEEauthorblockN{Andrés Felipe Ortega Montoya}
    \IEEEauthorblockA{\textit{Mathematical Engineering} \\
        Medellín, Colombia \\
        aortega7@eafit.edu.co}}

\maketitle

\listoftodos

\begin{abstract}
    Pulsars are a type of neutron star that need measurement over a prolonged
    time to assess their presence. In the current paper various Artificial
    Intelligence algorithms are used in order to predict pulsar star candidates.
    Multiple supervised and unsupervised algorithms are approached in this,
    comparing their efficiency. Alonside the predictors developed, the data and
    results are explored in depth and multiple indices are used to quantify the
    success of these.
\end{abstract}

\begin{IEEEkeywords}
    AI, Pulsar, Labeling
\end{IEEEkeywords}

\section{Introduction\label{sec:intro}} 
\todo[inline]{check all figure captions}
It is know that since ancient times humankind humankind has made an effort to
catalogue the stars visible in the sky, from the $36$ stars listed in the
\"three stars each\" by the ancient Babylonians in the $2000s\
B.C.$~\cite{astronomy:history:north}; to the last full-sky catalogue to date
with over $1.5$ billion objects, the Gaia Data Release 3~\cite{gaia:dr3:esa},
made available to the public on June 13, 2022, by the European Space Agency.

With the advent of modern telescopes and satellites, the capability to detect
even the dimmest lights from space have reached heights previously unthinkable.
The gaia catalogue is but one of the many catalogues available to date, which
serves to illustrate sheer quantity of data currently collected. Current
telescopes are constantly surveying the sky in search for evermore objects to
study.

This massive volume of data means that most of it will never get to be studied
by hand by astronomers, instead better focusing their efforts studying object
that are already known to possess qualities that may result of special interest.
In order to identify these special observations from the sea of data available,
multiple techniques have been developed~\cite{pulsar:dataset:explanation:lyon}.
In the current paper, data from a specialized pulsar
catalogue~\cite{pulsar:dataset:lyon}, is approached using multiple Artificial
Intelligence techniques in order to identify possible pulsar star candidates.

\todo[inline]{Section description}
In Section \ref{sec:problem} the astronomical phenomenom is described more in
depth along with the problem to tackle in this. Section \ref{sec:state_of_art}
Is a short compendium of how different authors have approached the problem
before. Section \ref{sec:premodel} deals with the steps previous to trying any
solutions, mostly data exploration and the sampling process. Section
\ref{sec:supervised} deals with the aprroaches that use the labeling offered
by the dataset while \ref{sec:unsupervised} tries a blindfolded approach to
possibly question any wrongly assignated labeling in the dataset.

\section{The problem\label{sec:problem}}

The name Pulsar (from\underline{Puls}ating st\underline{ar}) refers to rapidly
rotating and strongly magnetized neutron stars~\cite{pulsar:definition:nasa}.
The magnetic field present in these stars, accelerates particles to high speeds
around the star, which may ultimately get thrown into the magnetic poles poles
of the pulsar, heating them. This heat gradient gets to be so high that the
poles may act as hotspots, radiating massive amounts of heat into space,
distinctively more than that of the rest of the star. As the star spins, these
beams of electromagnetic waves (mostly on the X-ray spectrum) go in and out of
view from earth at extremely regular periods, motion that makes it appear as
pulsating in the sky, thus, giving it its name.

Pulsars get to occupy an special place in solving a wide range of physical and
astronomical problems~\cite{pulsar:importance:kramer}. The extreme conditions on
these allow to test the limits of gravitational theories, solid state physics
and plasma physics under extreme conditions among others. For most uses one
needs not to know how pulsars work but treating them as natural clocks with
stabilities similar to the best atomic clocks over time spans of months or
years. Correctly identifying these objects presents then a challenge worth
approaching.

Although over short periods of time, the signals received from each pulsar
varies slightly on each rotation~\cite{pulsar:importance:kramer}, it is possible
to make an appropriate labeling using average measures over longer periods of
time. In practice however, their dim signals means that almost all detections
are a result of radio frequency interference and
noise~\cite{pulsar:dataset:explanation:lyon}. creating the necessity of finding
new ways to differentiate real candidates from the rest.

\citet{pulsar:dataset:lyon} provides a dataset which contains a total of $17898$
data points, $1639$ for them corresponding to real pulsar detections (verified
by human annotators), and $16259$ detections associated to RFI or noise. The
dataset was modified and split in Kaggle~\cite{pulsar:dataset:kaggle} into one
unlabelled set with $5370$ observations and a labelled set with $12528$
observations, the latter being the one used on this paper for purposes of
training, testing, and validation of the techniques used.

As pulsars appear very dimmly in the sky, it is necessary to collect a few
hundred to thousand of pulses together in order to discern them from the
background noise, this collection is \textit{folded} into an integrated pulse
profile~\cite{pulsar:importance:kramer}. The dataset previously mentioned has 8
continuous variables per pulsar candidate, each with its corresponding binary
labeling. The first $4$ of them are statistics that describe the integrated
pulse profile of the star, while the last $4$ are similarly statistics from the
DM-SNR (Dispersion Measure - Signal to Noise
Ratio)~\cite{pulsar:dataset:explanation:lyon}. The task being then to decide
based on these 8 variables if any given object is a possible pulsar or not.

In the order that they appear on the database, the variables are:

\begin{table}[ht]
    \begin{tabular}{l|l}
        $X_0:$ & Mean of the integrated profile.\\
        $X_1:$ & Standard deviation of the integrated profile.\\
        $X_2:$ & Excess kurtosis of the integrated profile.\\
        $X_3:$ & Skewness of the integrated profile.\\
        $X_4:$ & Mean of the DM-SNR curve.\\
        $X_5:$ & Standard deviation of the DM-SNR curve.\\
        $X_6:$ & Excess kurtosis of the DM-SNR curve.\\
        $X_7:$ & Skewness of the DM-SNR curve.\\
        $Y:$   & Class 
    \end{tabular}
    \caption{Attributes describing a pulsar candidate\label{tab:variables}}
\end{table}

\section{Conceptual framework}

\todo[inline]{Conceptual framework}

\section{Methodology\label{sec:methods}}

\subsection{Visualization}

In order to start exploring the sample space, Figure \ref{fig:dist} has a
projection of variables $X_1$, $X_2$ and $X_6$, these being selected for their
greater dispersion as will be discused in Figure \ref{fig:sample:hist:variables}
on Section \ref{sec:sample:final}. The output class $Y$ is indicated by
colour, red if a given star is a pulsar or black otherwise. 

\begin{figure}[ht]
    \includegraphics[width=\linewidth]{dist}
    \caption{Projection of the data distribution. \label{fig:dist}}
\end{figure}

In this figure it can see that the data has two distinct cloud of points that
correspond with their classification. For the points labelled false, they clump
up into an sphere, and get scarser the further they are from the center of it.
The second cloud of points, corresponding to the identified pulsars, has a flat
shape which lies down and to the side of the former. The points seem to very
slightly group away from the non pulsars.

\subsection{Sampling process\label{sec:sample}}

With any proposed model the goal is to best approximate certain dynamic, having
but some sample of such event. Before applying any technique to tackle the
problem at hand, one may first decide how to construct an appropiate training
sample that best represents the desired phenomenom so as not to overfit the
model while retaining the dynamic of the system.

This sampling is done under a random distribution and it is usually desired to
have an equal representation of the labels in the sample than that present in
the original dataset. This being said, the data is to be splitted on $3$
mutually exclusive sets, one for training the models with $60\%$ of the original
data; and a test and validation sets with $20\%$ each. These last $2$ sets will
serve to observe the generability capacities of the models proposed.

The sampling for the current document was made by sampling instead an indexing
of the data with sequencial natural numbers starting from. To avoid the possible
case of introducing bias on the samples, $3$ sampling distributions where chosen
in order to compare their results and choose the best performing one. The
selected distributions being uniform, triangular, and normal distributions. As
the number of observations is finite, for continous distributions each index $x$
is given a probability of $f(x)$ (with $f$ being the PDF) and then it is scaled
so that the sum of the probability over all indices equals $1$. This
accomodation is made in order to use indistinctively discrete or continuous
distributions.

For a sample size $N$, the parameters for the before mentioned distributions 
are chosen as follows:
\begin{itemize}
    \item Uniform: spans from $0$ to $N$
    \item Triangular: mode of $N/2$, spans from $-1$ to $N+1$ so that indices on
        the extremes get a non zero probability
    \item Normal: mean of $N/2$, standard deviation of $N/6$
\end{itemize} 

Each distribution has a corresponding self-information function that measures
the ``surprisal'' of any outcome. The expected information of a given
probability distribution is called entropy~\cite{information:borda}. Under these
definitions one could argue that a distribution with a higher entropy
corresponds to a better sampling technique, one more informative.
Figure~\ref{fig:sample:info} then presents the probabily distributions selected
with their corresponding self-information and entropy.

\begin{figure}[ht]
    \includegraphics[width=\linewidth]{sample:info}
    \caption{Example of a figure caption. \label{fig:sample:info}}
\end{figure}

In the Algorithm~\ref{alg:sample} used to construct the sample groups, it can be
seen that the construction is done sequencially, meaning that each set will not
have available any of the previously selected data and any bias introduced by
the sampling method may propagate to other groups.

\begin{algorithm}[ht]
    $P = \{0.6,\ 0.2,\ 0.2\}$\\
    $P' \gets \{\}$\\
    $I \gets \{x:\ 0\leq x\leq \lvert S\rvert,\ x\in\mathbb{N}\}$\\
    \For{$p \in P$}{ $f(x) \gets \text{PDF} \textbf{ with support } I$\\
        $s \gets p\lvert S\rvert \textbf{ realizations from } f(x)$\\
        $P' \gets P' \cup \{s\}$\\
        $I \gets I - s$\\
    } \caption{Sampling algorithm\label{alg:sample}}
\end{algorithm}

When filling each of the sets as described in the previous algorithm, the $N$
realizations from the desired distribution are generated without replacement.
This is to comply with the definition of the $3$ being mutually exclusive. The
process of sampling without replacement involves that the indices generated are
removed from the support of the distribution and the probability for the
remaining points are normalized once again for the next realization.

With the motivation of contrasting the previously obtained results numerically;
a histogram of a sample from every PDF is made, higlighting the distribution of
the selected data over the different groups and, the representation of the
desired labels in each of them as seen in Figure~\ref{fig:sample:hist:index}.

\begin{figure*}[ht]
    \includegraphics[width=\linewidth]{sample:hist:index}
    \caption{Example of a figure caption. \label{fig:sample:hist:index}}
\end{figure*}


\subsection{Final sample disposition\label{sec:sample:final}}

As could be seen in Section \ref{sec:sample} with Figure \ref{fig:sample:info}
the uniform distribution results on the optimal entropy value; furthermore, as
expected, it results in an equal representation of all indices over the $3$ of
the desired sets. Contrasting this, it is possible to note that for both the
triangular and normal sampling there is an over-representation of the central
objects in the training set, while having an under-representation of these for
the training and validation sets, which may lead to an scenario where what the
model is trained for has little to no relation with what it is being tested
against.

However, regardless of the sampling PDF selected, the distribution of the labels
over all $3$ sets remains consistent, which may be an indicator supporting that the
dataset was previously scrambled or that the process of collecting the data is
uniform in nature.

This being said, the uniform sampling was selected as the distribution of
choice. Then, in order to better have a better idea of how the data is
distributed over the sets, in Figure~\ref{fig:sample:hist:variables} it is shown
how each of the variables previously mentioned in \ref{tab:variables} are
represented in the partitions. Although we can see that all variables are
properly sampled in the partitioned sets, it is interesting to point out that
variables $X_3, X_4$ and $X_7$ seem to be extremely bunched up into a single
value, with a few outliers far from this point. 

\begin{figure*}[ht]
    \includegraphics[width=\linewidth]{sample:hist:variables}
    \caption{Distribution of input variables over sampling \label{fig:sample:hist:variables}}
\end{figure*}

Before any sampling is done, and not to incur in any special treatment with
missing data, from the initial labelled dataset with $12528$ entries, $3255$ of
them where dropped for having empty entries for any variable. 

This being said, after sampling and for the purpose of better training all
models, every variable is normalized linearly into a value in the range $[0,1]$;
and for the output, 2 artificial and opposite boolean variables were created,
$Y_0$ and $Y_1$, where $Y_0$ is $1$ when the candidate is a pulsar, and $Y_1$ is
$1$ when it is not. This makes all the sample space and every possible
observation on it a point in a unitary hypercube.

The problem previously described for variables $X_3, X_4$ and $X_7$ is not going
to be tackled in the current work, although it could be approaced by using a
logarithmic normalization instead of a linear one so as to spread the central
spike and group the outliers on the extrema of the variable range (that being
$0$ or $1$).

\section{Results}

\subsection{Linear and logistic regression}
It is possible to observe in Figure \ref{fig:regression} the output of the model
for all points against variables $X_1$ and $X_2$. Both the linear and logistic
models assignated the same class for all points however, the logistic model has
a much sharper separation between the groups having assignated higher values
to both.

\begin{figure}[ht]
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=\linewidth]{regression:train}
        \caption{Linear and logistic regression for training data
        \label{fig:regression:train}}
    \end{subfigure}
    %
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=\linewidth]{regression:test}
        \caption{Linear and logistic regression for test data
        \label{fig:regression:test}}
    \end{subfigure}
    %
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=\linewidth]{regression:validation}
        \caption{Linear and logistic regression for validation data
        \label{fig:regression:validation}}
    \end{subfigure}
    \caption{Classification for linear and logistic regression
        \label{fig:regression}}
\end{figure}



\subsection{Performance}

\begin{table}    
    \begin{subtable}{0.49\linewidth}
        \csvreader[
            centered tabular=l|ll,
            no head,column count=3,
            table head=  & F & T \\\hline
        ]{../tables/regression:CM:train.csv}{}%
        {\ifcsvstrequal{\thecsvrow}{1}{F}{T} & \percentage{\csvcoli} & \percentage{\csvcolii}}%
        \caption{Confusion matrix for regression on train data\label{tab:regression:CM:train}}
    \end{subtable}
    \hfill%
    \begin{subtable}{0.49\linewidth}
        \csvreader[
            centered tabular=l|ll,
            no head,column count=3,
            table head=  & F & T \\\hline,
        ]{../tables/regression:CM:test.csv}{}%
        {\ifcsvstrequal{\thecsvrow}{1}{F}{T} & \percentage{\csvcoli} & \percentage{\csvcolii}}%
        \caption{Confusion matrix for regression on test data\label{tab:regression:CM:test}}
    \end{subtable}

    \begin{subtable}{\linewidth}
        \csvreader[
            centered tabular=l|ll,
            no head,column count=3,
            table head= & F & T \\\hline,
            late after line=\\\hline
        ]{../tables/regression:CM:validation.csv}{}%
        {\ifcsvstrequal{\thecsvrow}{1}{F}{T} & \percentage{\csvcoli} & \percentage{\csvcolii}}%
        \caption{Confusion matrix for regression on validation data\label{tab:regression:CM:validation}}
    \end{subtable}
    \caption{Confusion matrix for regression models\label{tab:regression:CM}}
\end{table}


\begin{table}
    \hfill
    \begin{subtable}{0.45\linewidth}
        \csvreader[
            centered tabular=l|l,
            no head,column count=2,
            table head= Index & Value \\\hline
        ]{../tables/regression:index:train.csv}{}%
        {\csvcoli & \csvcolii}%
        \caption{Multiple indices on training data\label{tab:regression:index:train}}
    \end{subtable}
    \hfill%
    \begin{subtable}{0.45\linewidth}
        \csvreader[
            centered tabular=l|l,
            no head,column count=2,
            table head= Index & Value \\\hline
        ]{../tables/regression:index:test.csv}{}%
        {\csvcoli & \csvcolii}%
        \caption{Multiple indices on test data\label{tab:regression:index:test}}
    \end{subtable}
    \hfill

    \begin{subtable}{\linewidth}
        \csvreader[
            centered tabular=l|l,
            no head,column count=2,
            table head= Index & Value \\\hline
        ]{../tables/regression:index:validation.csv}{}%
        {\csvcoli & \csvcolii}%
        \caption{Multiple indices on validation data\label{tab:regression:index:validation}}
    \end{subtable}
    \caption{Multiple indices on regression models\label{tab:regression:index}}
\end{table}


\section{Supervised learning\label{sec:supervised}} 

Supervised learning is called when both inputs and outputs for a given problem
are used in order to mimic the underlying behaviour and simulate its dynamic
\cite{supervised:definition:rusell}. The ouput for our problem is present and is
revised by actual human annotators, so a supervised approach may be a good start
to analyse the data. In the following sections multiple supervised techniques
are described and compared agains multiple indices.

\subsection{Linear and logistic regression\label{sec:regression}}

Linear regression is probably the simplest way of tuning parameters to follow
given data. It assumes a matrix $X$ of $n$ measured variables over $p$
observations, a matrix $Y$ with $m$ output variables over the same opulation,
and a matrix $\beta$ relating them. It assumes, as its name implies, that the
dynamic of the model can be expressed as a linear equation of the form: 
%
\begin{equation}\label{eq:linear}
    \overset{(m\times p)}{Y}
    = \overset{(m\times n)}{\beta} \overset{(n\times p)}{X}
\end{equation}
%
Where it is desired to find the best parameter $\beta$. This can be done making
use of the pseudo inverse of $X$ as follows:
%
\begin{align*}
    \overset{(m\times p)}{Y}
        &= \overset{(m\times n)}{\beta} \overset{(n\times p)}{X}\\
    \overset{(m\times p)}{Y}\overset{(p\times n)}{X^T}
        &= \overset{(m\times p)}{\beta X} \overset{(p\times n)}{X^T}\nonumber\\
    \overset{(m\times n)}{Y X^T} \overset{(n\times n)}{\left(X X^T\right)^{-1}}
        &= \overset{(m\times n)}{\beta}
\end{align*}
%
It's important to note that usually a row of $1$s is added to $X$ in order to
account for a constant term in the model. A similar model is logistic
regression, which deals with data in the range $(0, 1)$ that have a great
distinction between then, making it especially useful for problems of
classification. It assumes a model of the form:
%
\begin{equation}
    Y = \frac{1}{1+\exp{(-\beta X)}}
\end{equation}
%
Where addition, division, and exponentiation are defined elementwise; which
imposes multiple and simultaneous sigmoid functions of $1$ output. 
This model can be solved as a linear regression with the substitution:
%
\begin{align*}
    Y &= \frac{1}{1+e^{(-\beta X)}}\nonumber\\
        &= \frac{e^{(\beta X)}}{1+e^{(\beta X)}}\\
    Y+Ye^{(\beta X)}
        &= e^{(\beta X)}\\
    Y &= (1-Y) e^{(\beta X)}\\
    \frac{Y}{1-Y} &= e^{(\beta X)}\\
    \ln{\left(\frac{Y}{1-Y}\right)} &= \beta X\\
        &= P
\end{align*}
%
Using the known output $Y$ to find $P$, solving for $\beta$ in the new linear
model, and substituting everything back into the original expression.



\subsection{Multilayer perceptron\label{sec:nn}}
\todo[inline]{nn describe}

\section{Unsupervised leaning\label{sec:unsupervised}}
\printbibliography
\end{document}
    